# Q6.3 모델 학습 분산

**🙋 질문 : 분산 인스턴스에서 모델을 학습시키는 방법에는 무엇이 있나요?**

**🗣️모델 학습을 분산시키는 방법에는 데이터 병렬 처리와 모델 병렬 처리가 있습니다.**

## 1. 데이터 병렬 처리

- 각 작업자 노드<sup>worker node</sup>는 모델 전체의 복사본을 사용하게 되며, **데이터가 노드 간에 분할됨**
- **각 노드는 할당받은 데이터에 대한 경사를 계산하고** 경삿값들을 모아서 모델 매개변수를 업데이트

### 1-1. 동기식 데이터 병렬 처리

- 모든 작업자 노드가 **동시에 경사를 계산**하고, 모델을 업데이트 하기 전에 이를 집계
- **업데이트된 경사들의 복사본이 모든 작업자 노드에 전송됨**
- 장점: 작업자들이 항상 동일한 모델 매개변수를 갖게 됨
- 단점: 학습 속도가 느려질 수 있음

### 1-2. 비동기식 데이터 병렬 처리

- 각 작업자 노드가 경사를 독립적으로 계산하고, 한 노드가 계산을 완료할 때마다 모델 매개변수 업데이트
- 장점: 작업자 노드 간에 **계산 능력 편차가 있을 때 유용**
- 단점: 상대적으로 약간 오래된<sup>stale</sup> 모델 버전을 사용하게 됨

### 1-3. 데이터 병렬 처리 구현 방법

#### 1-3-1. 중앙 집중형

- 매개변수 서버에 모델 매개변수를 저장
  - 학습 과정에서 작업자 노드는 매개변수 서버와 통신해 모델 매개변수를 가져옴
  - 작업나 노드는 경사값 업데이트를 매개변수 서버에 보냄
- 장점: 경사 계산과 모델 업데이트 작업을 분리해 모델 상태 관리 작업을 단순화
- 단점: 매개변수 서버가 통신 병목이 될 수 있음

#### 1-3-2. 분산형

- 작업자 노드 간에 통신해 모델 매개변수를 업데이트
- 링 올리듀스<sup>Ring AllReduce</sup>
  - 작업자 노드가 링 토폴로지상의 이웃 노드와 통신해 경사를 집계
  - 경삿값은 링을 따라 시계 방향으로 전송됨
    - 각 노드는 수신한 경삿값을 자신의 경삿값과 결합
    - 모든 노드가 경삿값 결합을 완료할 때까지 과정을 지속
  - 최종 집계된 경삿값은 링을 따라 각 노드로 다시 전송됨
  - 각 노드는 이 집계된 경삿값으로 모델 복사본을 업데이트

## 2. 모델 병렬 처리

- 모델이 단일 디바이스나 노드의 메모리에 담기에 너무 클 때 사용
- 작업자 노드들이 **모델의 서로 다른 부분**을 할당 받음
  - 모델을 수평<sup>레이어 내부 분할</sup> 또는 수직<sup>레이어 간 분할</sup>으로 분할
- 각 노드는 **할당받은 부분에 대한 경사를 계산**
- 노드 간 통신으로 순방향 및 역방향 계산에서 매개변수들을 공유함

---

<center>
    <img 
    src="https://i.imgur.com/5bhjElS.png" width="50%" 
    height="50%" 
    title=""/>
    <figcaption>
        Data parallelism and model parallelism
    </figcaption>
</center>

<p style="text-align: center;">
    출처:https://www.anyscale.com/blog/what-is-distributed-training#data-parallelism-and-model-parallelism
</p>
