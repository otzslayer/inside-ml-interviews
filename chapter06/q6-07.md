# Q6.7 모델 최적화

**🙋 질문 : 매우 짧은 지연 시간을 갖도록 학습한 모델을 최적화하는 방법에는 무엇이 있나요?**

**🗣️ 피처 선택, 레이어 수 축소, 레이어 크기 축소 등 기존 기법은 이미 적용됐다고 가정하고, 다음 서빙을 위해 모델을 추가로 최적화하는 기법입니다.**

## 1. 모델 정리

- 모델의 예측 경로에 존재하는 불필요한 구성 요소 제거
  - 사용되지 않는 노드, 중복 노드, 학습과 달리 예측에 필요 없는 기타 구성 요소 등
- 배치 정규화의 곱셈을 이전 레이어의 가중치 곱셈에 통합

## 2. 입력 압축

- 학습 중에 대상 및 후보 피처에 대한 임베딩을 저장해둔 후 추론 시에 그 임베딩들만 가져오는 방법
- 피처가 모델에 전달되는 포맷도 고려 -> `tf.Example` 타입 재검토

## 3. 효율적 캐싱 전략

- 피처의 캐싱은 인스턴스와 데이터 센터 수준 모두에서 할 수 있으므로 지연 시간과 캐시 적중률을 최적화할 수 있음
- 개별 피처 대신 임베딩을 캐시해 피처 공간 밀도를 높이고 지연 시간을 주일 수 있음

## 4. 일괄 추론

- 네트워크 트래픽과 인스턴스별 계산 로드 간의 규형 유지
  - 각 요청의 배치 크기를 조정
  - 랭킹 모델에서 특히 후보가 많은 경우 모델 서버 네트워크 처리량이 문제가 될 수 있음

## 5. 투 타워

- `SplitNet` 또는 `벡터곱 DNN` - 기존 `DNN`을 병렬 하위 신경망 두 개로 분할 - 한쪽 신경망에 대상 피처, 다른 쪽에 후보 피처 제공 - 각 신경망은 각각 타깃 임베딩과 후보 임베딩을 나타내는 고정 크기 벡터 출력 - 최종 예측 점수는 벡터의 내적에 시그모이드 활성화 적용 - 트위터와 같이 랭킹 모델을 사용하는 회사에서 주로 사용 061

## 6. 양자화

- 가중치 및 활성화 출력의 정밀도를 `float32`에서 `int8`이나 바이너리로 줄여 계산 시간을 줄임

## 7. 효율적인 신경망 제품군

- 컨볼루셔널 레이어를 그룹화하는 ShuffleNet, MobileNet, EfficientNet 등 효율적인 신경망 제품군 사용
  - ShuffleNet [Introduced by Zhang., et al.](https://paperswithcode.com/method/shufflenet)
  - MobileNet [Introduced by Howard, Andrew G., et al.](https://paperswithcode.com/paper/mobilenets-efficient-convolutional-neural)
  - EfficientNet [Introduced by MingXing Tan,. et al.](https://paperswithcode.com/paper/efficientnet-rethinking-model-scaling-for)

## 8. 모델 압축

- 최근 발전하고 있는 모델 압축 기술의 활용
  - 지식증류 [Introduced by Cho, J. H., et al.](https://arxiv.org/abs/1910.01348)
  - 가중치 행렬의 낮은 랭크 근사 [Introduced by MA, Yuzhe, et al.](https://ieeexplore.ieee.org/abstract/document/8995407)
  - DNN의 입력 레이어 압축 [Introduced by NAKKIRAN, Preetum, et al.](https://www.isca-archive.org/interspeech_2015/nakkiran15_interspeech.pdf)
  - 모델 성능에 기여도가 낮은 가중치 및 연결 가지치기 [Introducedby HAN, Song, et al.](https://proceedings.neurips.cc/paper/2015/hash/ae0eb3eed39d2bcef4622b2499a05fe6-Abstract.html)
  - 레이어 클러스트링을 통한 가중치 공유 [Weight clustering](https://www.tensorflow.org/model_optimization/guide/clustering)
  - 입력에 따라 DNN의 하위 영역을 활성화하는 동적 DNN Introducec by HAN, Yizeng, et al.(https://ieeexplore.ieee.org/abstract/document/9560049)

> [!Tip]
>
> - 텐서플로 모델 최적화 기술 참고 [Optimizing TensorFlow Models for Serving](https://medium.com/google-cloud/optimizing-tensorflow-models-for-serving-959080e9ddbf)
>
> - 다양한 양자화 전략 참고 [Model optimization](https://www.tensorflow.org/lite/performance/model_optimization#quantization)
