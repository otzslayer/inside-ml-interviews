# Q6.10 피처 수화 개선

**🙋 질문 : 서빙 타임에 피처 수화<sup>hydration</sup> 및 처리 속도를 높이는 방법은?**

## 1. 조회 최적화

- 피처 저장 및 검색 과정 개선
  - 정적 참조 피처(ex. 인구 통계학적 요소)
    - 오프라인 프로세스 : 데이터 웨어하우스에서 엔터티 데이터를 읽고 피처 엔지니어링을 수행한 후 빠르게 조회가 가능한 스토어에 피처 저장
  - 동적 실시간 피처(ex. 일정 기간 내 빈도)
    - 스트리밍 파이프라인 : 실시간으로 이벤트를 포착하고 집계하며 실시간 집계 결과는 빠르게 조회가 가능한 스토어에 저장

## 2. 캐싱

- 캐시를 통한 지연 시간 단축
  - 추출된 피처, 자주 참조되는 피처, 예측 점수를 캐싱하는 등
  - 개별 인스턴스와 데이터 센터 수준 모두에서 일어날 수 있음
  - 웜 스타트 상황에서 선제적으로 수행되기도 함

## 3. 다단계 수화

- 다양한 시점에 피처 수화는 발생할 수 있음
  - 추천 요청의 경우 다음 두 가지를 병렬로 수행할 수 있음
    - 요청 처리 시작 시 후보 생성 작업과 대상 피처를 처리하도록 함

## 4. 밀집화

- 원본 데이터를 모델 입력에 더 적합한 형식으로 저장하여 Fetch 지연 시간 단축

## 5. 사전 계산

- 파생 피처를 미리 계산해 저장 장치에 보관함으로써 처리 시간 단축

## 6. 피처 그룹화

- 피처를 논리적 그룹으로 구성하고 함께 저장해 네트워크 혼잡을 줄임

## 7. 병렬 처리

- 병렬 처리 기술을 사용해 피처 수화와 처리를 동시에 진행
  - 여러 데이터 소스에서 피처를 병렬로 가져오고 결합하여 예측 단계로 보냄

## 8. 동일 인스턴스

- 피처 추출 및 예측을 동일 인스턴스에서 수행하여 피처를 모델 서버로 보내는 수고를 줄임
- 다만 여러 모델 서버에 걸쳐 데이터가 일괄 처리되는 경우에는 적용할 수 없음

> [!Tip]
> 지연 시간이 짧은 조회 데이터 스토어의 예로는, 읽기를 위한 구글의 데이터스토어<sup>Datastore</sup>와 읽기/쓰기를 위한 빅데이블<sup>Bigtable</sup>이 있음. 이 외에 Feast와 같은 피처 스토어를 사용한 서빙 피처 관리도 고려해볼 수 있음 [Read Blog](https://cloud.google.com/blog/products/ai-machine-learning/introducing-feast-an-open-source-feature-store-for-machine-learning?hl=en)
