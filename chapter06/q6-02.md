# Q6.2 모델 학습 가속화

**🙋 질문 : 단일 인스턴스에서 모델 학습 속도를 높이는 방법에는 무엇이 있나요?**

**🗣️모델 아키텍처 변경이나 추가 피처 엔지니어링이 없는 경우, 단일 인스턴스에서의 모델 학습 속도를 높이기 위해 다음 기법을 적용할 수 있습니다.**

## 1. 데이터 로드 시간 최소화하기

- 패키지에서 제공되는 기본 기능을 사용하여 데이터 추출, 변환, 로드 작업을 하는 경우 효율성 측면에서 재검토
  - 예) 데이터 로드 작업시 TFX 파이프라인 구성요소<sup>ex. BigQueryExampleGen</sup>의 사용이 편리할 수 있지만, 데이터셋을 디스크에 TFRecord로 저장하고 데이터를 직접 읽어들이는 편이 더 효율적일 수 있음
  - 예) TF Transform을 활용한 정규화의 경우 대규모 데이터셋에서 느리게 작동한다고 알려져 있음 → 데이터셋을 샘플링해 케라스 정규화 레이어를 적용하는 편이 더 빠를 수도 있으므로 재검토 필요

> BigQueryExampleGen는 TFX에서 제공하는 컴포넌트 중 하나로, 구글의 BigQuery에서 데이터를 추출해서 TFX 워크플로우에서 활용할 수 있는 Example 프로토콜 버퍼 형식으로 변환하는데 사용됨

## 2. 큰 배치 사용하기

- 배치가 클수록 매개변수 업데이트 횟수를 줄여 학습 속도를 높일 수 있음
  - 다만 배치가 작을 때와 비교해 비슷한 수준의 정확도를 달성하려면 더 많은 에포크<sup>epoch</sup>가 필요할 수 있음

## 3. 학습률 일정 최적화하기

- 학습률 일정을 미세 조정해 수렴 속도와 최적화 프로세스 안정성 간의 균형 도모

## 4. 계산 부담이 적은(비용이 낮은) 그래디언트

- ReLU나 PReLU<sup>Parametric ReLU</sup>와 같이 그래디언트 계산 비용이 낮은 활성화 함수 사용

## 5. 최적화된 구현 사용하기

- 최적화된 구현이 포함된 라이브러리와 프레임워크의 사용

## 6. 단일 인스턴스 병렬 처리하기

- [Hogwild!](https://arxiv.org/abs/1106.5730)의 사용: 확률적 경사하강법의 배치 수준 병렬화, 행렬곱 및 기타 선형 대수 연산의 병렬화

## 7. GPU 가속 기능 활용하기

- GPU는 병렬 처리에 최적화 되어 있고, 메모리 대역폭이 크며, 행렬 계산에 특화된 설계가 되어 있어 학습 시간을 크게 단축시킴

## 8. 스마트한 초기화

- 매개변수의 좋은 시작 값은 수렴 속도와 성능 향상에 도움이 됨
  - 예) 평균이 0이고 목표 분산값<sup>target variance</sup>을 가지는 정규분포<sup>Glorot 또는 Xavier</sup>로 초기화
  - 예) 이전에 학습된 모델 버전의 매개변수로 초기화

## 9. 배치 정규화

- 모델의 각 레이어에 대한 입력을 정규화<sup>normalization</sup>해 활성화 출력이 너무 커지거나 작아지는 것을 방지

## 10. 다운샘플링

- 불균형 클래스가 있는 데이터셋에서 특정 클래스를 다운샘플링하면 학습 속도가 빨라지고 모델 성능 향상도 기대할 수 있음
