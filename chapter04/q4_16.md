# Q4.16 임베딩 기술

> [!Tip]
>
> 🙋  행렬 분해를 설명하세요.

-   2010년대 대부분에는 추천 후보 생성에 행렬 분해<sup>Matrix Factorization</sup>(MF)를 많이 사용함
    -   [Koren, Yehuda. "Factorization meets the neighborhood: a multifaceted collaborative filtering model." *Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining*. 2008.](https://velog.io/@tobigs-recsys/Paper-Review-KDD-2008-Factorization-meets-the-neighborhood-a-multifaceted-collaborative-filtering-model)
    -   페이스북은 2015년에 아이템 추천을 위해 MF를 구현함
        -   Ilic, Aleksandar., & Kabiljo, Maja. (2015, June 2). Recommending items to more than a billion people. Engineering at Meta. Retrieved July 1, 2024, from https://engineering.fb.com/2015/06/02/core-infra/recommending-items-to-more-than-a-billion-people/
-   행렬 분해 기법은 평가 행렬<sup>rating matrix</sup>을 분해해 사용자 및 아이템에 대한 임베딩을 학습함

-   특잇값 분해<sup>Singular Value Decomposition</sup> (SVD)

    -   사용자-아이템 상호 작용 행렬의 정보 손실을 최소화하면서 낮은 차원 공간에서 표현하기 위해 low-rank approximation을 사용
    -   원래 행렬을 왼쪽, 특잇값 행렬, 오른쪽으로 분해하는데 왼쪽 행렬을 임베딩으로 간주함

-   가중 행렬 분해<sup>Weighted Matrix Factorization</sup>

    -   목적 함수는 관찰된 쌍에 대한 오차를 최소화하기 위한 항과 관찰되지 않은 쌍에 오차를 최소화하기 위한 항으로 구성

    -   가중치를 목적 함수에 통합하여 희소성이 높은 데이터셋을 처리할 수 있음

    -   $$
        \min_{U \in \mathbb{R}^{m \times d}, V \in \mathbb{R}^{n \times d}} \sum_{(i, j) \in \text{obs}} \left( A_{ij} - \langle U_i, V_j \rangle \right)^2 + w_0 \sum_{(i, j) \not\in \text{obs}} \left( \langle U_i, V_j \rangle \right)^2
        $$

        -   $A$ : 사용자-아이템 상호 작용의 희소 행렬
        -   $\langle U_i, V_j \rangle$ : 사용자와 아이템 임베딩의 내적
        -   $w_0$ : 두 항의 균형을 맞추기 위한 하이퍼파라미터

    -   최적화에는 SGD, Weighted Alternating Least Squares(WALS) 등 사용

        -   WALS는 사용자 임베딩과 아이템 임베딩을 번갈아 업데이트하는 방식

-   행렬 분해는 사용자와 아이템 피처의 상호 작용을 효과적으로 담아내는 데 어려움이 있음

    -   Second-order 까지의 피처 상호 작용을 포착하기 위한 다음의 시도가 있었음
        -   SVDFeature
            -   [Chen, Tianqi, et al. "SVDFeature: a toolkit for feature-based collaborative filtering." *The Journal of Machine Learning Research* 13.1 (2012): 3619-3622.](https://www.jmlr.org/papers/volume13/chen12a/chen12a.pdf)
        -   Factorization Machine
            -   [Rendle, Steffen. "Factorization machines." *2010 IEEE International conference on data mining*. IEEE, 2010.](https://jame-zhang.github.io/assets/algo/Factorization-Machines-Rendle2010.pdf)




> [!Tip]
>
> 🙋  심층 신경망을 설명하세요.

-   추천 정확도를 향상하는데 MF보다 DNN이 더 효과적임이 입증됨
    -   [He, Xiangnan, et al. "Neural collaborative filtering." *Proceedings of the 26th international conference on world wide web*. 2017.](https://otzslayer.github.io/ml/2021/12/12/neural-collaborative-filtering.html)
    -   CNN은 MF에 비해 비선형적인 특성이 있어 복잡한 피처 상호 작용을 더 효율적으로 포착함
    

### 시퀀스 모델<sup>Sequence model</sup>

-   시퀀스 모델을 사용해 후보 생성을 위한 사용자 및 아이템 임베딩을 생성함
    -   사용자의 상호 작용 이력을 아이템의 시퀀스처럼 처리
    -   NLP 모델은 아이템과 사용자 선호도 사이의 순차적인 종속성을 포착하는 임베딩을 학습함
    -   최근에는 어텐션 매커니즘과 트랜스포머를 활용하는 모델이 개발됨
-   예시
    -   에어비앤비<sup>AirBnb</sup>
        -   [Grbovic, Mihajlo, and Haibin Cheng. "Real-time personalization using embeddings for search ranking at airbnb." *Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining*. 2018.](https://github.com/wzhe06/Ad-papers/blob/master/Embedding/%5BAirbnb%20Embedding%5D%20Real-time%20Personalization%20using%20Embeddings%20for%20Search%20Ranking%20at%20Airbnb%20(Airbnb%202018).pdf)
    -   크리테오<sup>Criteo</sup>
        -   [Vasile, Flavian, Elena Smirnova, and Alexis Conneau. "Meta-prod2vec: Product embeddings using side-information for recommendation." *Proceedings of the 10th ACM conference on recommender systems*. 2016.](https://arxiv.org/pdf/1607.07326)
    -   엣시<sup>Etsy</sup>
        -   [Zhao, Xiaoting, et al. "Learning item-interaction embeddings for user recommendations." *arXiv preprint arXiv:1812.04407* (2018).](https://arxiv.org/pdf/1812.04407)
    -   야후
        -   [Okura, Shumpei, et al. "Embedding-based news recommendation for millions of users." *Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining*. 2017.](https://dacemirror.sci-hub.se/proceedings-article/b79bf692bc190d28d255671a64aedf02/okura2017.pdf)

### 그래프 신경망<sup>Graph Neural Network (GNN)</sup>

<img src="https://miro.medium.com/v2/resize:fit:1400/1*Lm2eINM6KaSAhQzrbst8tA.png" alt="img" style="zoom:50%;" />

Image from [Here](https://towardsdatascience.com/graph-convolutional-networks-deep-99d7fee5706f)

-   Graph Convolutional Network (GCN)
    -   재귀적으로 컨볼루션을 수행해 노드의 로컬 이웃으로부터 피처 정보를 수집하고 결합하는 방법을 학습
    -   컨볼루션 작업은 노드와 직결된 이웃들로부터 피처 정보를 모아 이를 dense하게 변환
    -   컨볼루션 레이어의 중첩을 통해 그래프 내의 정보가 거리가 먼 노드까지 전파됨
    -   로컬 및 글로벌 그래프 구조 모두 포착 가능
-   예시
    -   PinSage / PinnerSage
        -   [Pal, Aditya, et al. "Pinnersage: Multi-modal user embedding framework for recommendations at pinterest." *Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining*. 2020.](https://dl.acm.org/doi/pdf/10.1145/3394486.3403280)

### 투 타워 아키텍처<sup>Two-tower Architecture</sup>

-   SplitNet 또는 벡터 곱<sup>vector-product</sup> 모델이라고도 함
    -   사용자 및 아이템 피처를 처리하는 두 하위 DNN으로 나누며 둘 사이에는 교차 피처가 없음
    -   각 네트워크의 출력은 각각 사용자 및 아이템 임베딩을 나타내는 고정 크기 벡터
    -   내적이나 아다마르<sup>Hadamard</sup> 곱 등을 사용해 스코어 계산
-   신규 사용자나 아이템의 임베딩을 이력 없이 독립적으로 생성할 수 있다는 이점이 있음
    -   사용자와 아이템 네트워크를 격리하기 때문에 가능
-   예시
    -   구글
        -   [Yi, Xinyang, et al. "Sampling-bias-corrected neural modeling for large corpus item recommendations." *Proceedings of the 13th ACM Conference on Recommender Systems*. 2019.](https://research.google/pubs/sampling-bias-corrected-neural-modeling-for-large-corpus-item-recommendations/)
    -   트위터
        -   Wong, Jing Ping. (2022, January 20). Model-based candidate generation for account recommendations. X Engineering Blog. Retrieved July 1, 2024, from https://blog.x.com/engineering/en_us/topics/insights/2022/model-based-candidate-generation-for-account-recommendations#




> [!Tip]
>
> 🙋  그래프 임베딩을 설명하세요

-   그래프 임베딩<sup>Graph embedding</sup>
    -   대규모 네트워크의 노드를 컴팩트한 저차원 표현으로 변환하는 데 사용
    -   트위터에서 개발한 커뮤니티 기반 그래프 임베딩 방식: SimClusters
        -   [Satuluri, Venu, et al. "Simclusters: Community-based representations for heterogeneous recommendations at twitter." *Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery & data mining*. 2020.](https://github.com/twitter/the-algorithm/tree/main/src/scala/com/twitter/simclusters_v2?ref=graphusergroup.com)
        -   임베딩의 각 차원은 유사한 팔로워들의 클러스터인 커뮤니티로 표현됨
-   임베딩이 만들어지는 순서
    1.   Follow 그래프 생성
         -   Follower-followee 행렬 생성 (Consumer-producer 행렬이라고도 함)
    2.   Producer-producer 행렬 생성
         -   Follow 그래프 상에서 생산자 쌍 간에 팔로워 집합이 얼마나 겹치는지를 코사인 유사도가 되도록 생성
    3.   KnownFor 행렬 생성
         -   Metropolis-Hastings 알고리즘을 적용해 그래프를 $k$ 개의 커뮤니티로 나눠 밀도를 높임
             -   이 결과로 KnownFor 행렬이 생성됨
             -   Producer-producer 행렬의 저차원 표현이며 producer와 특정 커뮤니티의 follower 사이의 유사도를 나타냄
    4.   사용자 임베딩 계산
         -   Follow 그래프에 KnownFor 행렬을 곱해 사용자 임베딩을 계산
             -   해당 사용자가 팔로우하는 사람을 기준으로 사용자와 각 커뮤니티 사이의 유사도를 나타냄
             -   이 임베딩은 사용자 InterestedIn 임베딩이라고도 함
    5.   아이템 임베딩 계산
         -   아이템에 '좋아요'를 누른 사용자들의 InterestedIn 벡터를 집계해 계산
         -   다른 상호 작용도 사용할 수 있음



-   이종 정보 네트워크(Heterogeneous Information Network, HIN)
    -   [Shi, Chuan, et al. "A survey of heterogeneous information network analysis." *IEEE Transactions on Knowledge and Data Engineering* 29.1 (2016): 17-37.](https://dacemirror.sci-hub.se/journal-article/1880f90cba58360773d4e4fcf07fc515/shi2016.pdf)
    -   HIN을 사용하면 여러 유형의 엔티티(사용자, 아이템)와 이들 간의 다양한 유형의 관계를 포함하는 네트워크를 모델링할 수 있음
    -   각 엔티티와 관계는 임베딩 벡터로 표현됨
    -   HIN은 그래프 임베딩 생성을 위해 소스 엔티티, 관계 유형, 대상 엔티티로 구성된 삼중항에 스코어링 함수 적용
        -   TransE
            -   [참고 자료](https://otzslayer.github.io/cs224w/2023/07/02/cs224w-10.html#transe)
        -   스코어링 함수는 소스 엔티티의 임베딩을 가져와 관계 임베딩을 적용해 변환하고 대상 엔티티 임베딩과의 내적으로 점수 계산
    -   모델 학습을 위해 margin-based ranking criterion을 사용
        -   위 링크 참고
        -   트위터는 HIN에 기반을 둔 TwHIN 이라는 모델 적용
            -   [El-Kishky, Ahmed, et al. "Twhin: Embedding the twitter heterogeneous information network for personalized recommendation." *Proceedings of the 28th ACM SIGKDD conference on knowledge discovery and data mining*. 2022.](https://arxiv.org/pdf/2202.05387)
-   마이크로소프트의 LINE
    -   [Tang, Jian, et al. "Line: Large-scale information network embedding." *Proceedings of the 24th international conference on world wide web*. 2015.](https://arxiv.org/pdf/1503.03578.pdf)
    -   임베딩을 고려해 그래프에서 1차 및 2차 엣지를 관찰할 확률을 최대화하는 그래프 임베딩 기법