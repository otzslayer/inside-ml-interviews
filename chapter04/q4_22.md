# Q4.22 사전 랭킹 모델 알고리즘

> [!Tip]
>
> 🙋  사전 랭킹 모델에 적합한 알고리즘은 무엇인가요?

-   휴리스틱, 로지스틱 회귀, 투 타워, 경량 DNN 등을 사용해왔음



> [!Tip]
>
> 🙋  휴리스틱에서 로지스틱 회귀로 발전해간 과정을 설명하세요.

-   [McMahan, H. Brendan, et al. "Ad click prediction: a view from the trenches." *Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining*. 2013.](https://dl.acm.org/doi/pdf/10.1145/2487575.2488200)
-   처음에는 평균 예측 참여도, 후보 출처 및 알고리즘 인터리빙과 같은 휴리스틱적인 비개인화 기법을 사용
-   나중에는 학습이 빠르면서 지속적 학습으로 업데이트에 용이한 로지스틱 회귀 모델로 대체됨




> [!Tip]
>
> 🙋  로지스틱 회귀에서 투 타워로 발전해간 과정을 설명하세요.

<img src="https://miro.medium.com/v2/resize:fit:1400/1*JbK2gjfLC4IFoM6AVWLaUQ.png" alt="img" style="zoom:33%;" />

Image from [Here](https://medium.com/tech-p7s1/video-recommendations-at-joyn-two-tower-or-not-to-tower-that-was-never-a-question-6c6f182ade7c)

-   로지스틱 회귀에서 투 타워 아키텍처로 대체됨
-   투 타워 아키텍처
    -   하나의 신경망은 사용자 피처를 입력 받고, 다른 신경망은 아이템 피처를 입력 받음
        -   둘 사이에 교차 피처는 없음
    -   각 신경망의 출력 단계에서 사용자와 아이템에 대한 임베딩을 타나내는 고정 크기의 벡터를 얻음
        -   서빙 시에는 임베딩을 가져와서 내적을 계산해 효율적인 예측을 진행함
    -   마지막 단계에서는 내적 대신 시그모이드 함수를 적용하기도 함
        -   트위터에서는 내적 대신 아다마르 곱을 사용함
            -   Wang Hongjian. (2020, June 8). A new approach: Metric learning for SplitNet. X Engineering Blog. Retrieved July 6, 2024, from https://blog.x.com/engineering/en_us/topics/insights/2020/a-new-approach-metric-learning-for-splitnet
-   예시
    -   유튜브
        -   [Covington, Paul, Jay Adams, and Emre Sargin. "Deep neural networks for youtube recommendations." *Proceedings of the 10th ACM conference on recommender systems*. 2016.](https://static.googleusercontent.com/media/research.google.com/ko//pubs/archive/45530.pdf)
    -   트위터
        -   [Dilipkumar, D., & Chen, J. (2019, June 25). A SplitNet architecture for ad candidate ranking. Twitter Blog. Retrieved June 3, 2024.](https://blog.x.com/engineering/en_us/topics/infrastructure/2019/splitnet-architecture-for-ad-candidate-ranking)
    -   알리바바
        -   [Wang, Zhe, et al. "Cold: Towards the next generation of pre-ranking system." *arXiv preprint arXiv:2007.16122* (2020).](https://arxiv.org/pdf/2007.16122)




> [!Tip]
>
> 🙋  투 타워에서 경량 DNN으로 발전해간 과정을 설명하세요.

-   투 타워 기법의 단점
    -   교차 피처를 사용할 수 없음
        -   교차 피처는 추천 시스템 성능 최적화에 필수이며, 종종 피처 중요도 분석에서 높은 중요도를 가짐
-   경량 DNN
    -   캐싱과 모델 압축 같은 다양한 최적화 기술을 사용해 투 타워 속도에 근접할 수 있음
    -   알리바바의 COLD 모델
        -   [Wang, Zhe, et al. "Cold: Towards the next generation of pre-ranking system." *arXiv preprint arXiv:2007.16122* (2020).](https://arxiv.org/pdf/2007.16122)
        -   모델 아키텍처의 복잡성을 동적으로 조정하기 위해 Squeeze-and-Excitation (SE) 블록이 있음
            -   [Hu, Jie, Li Shen, and Gang Sun. "Squeeze-and-excitation networks." *Proceedings of the IEEE conference on computer vision and pattern recognition*. 2018.](https://medium.com/@parkie0517/squeeze-and-excitation-networks-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0-213bf3ec71cd)
