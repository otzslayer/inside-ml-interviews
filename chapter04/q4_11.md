# Q4.11 서빙 편향 완화

> [!Tip]
>
> 🙋  서빙 시의 편향을 어떻게 완화하나요?

-   피드백 루프로 인해 서빙 편향이 발생함
    -   모델이 노이즈를 학습해 유망한 추천 후보를 탐색할 수 없게 될 수 있음
-   따라서 활용/탐색 트레이드오프<sup>Exploration/Exploitation trade-off</sup>는 추천 시스템에서 매우 중요함
    -   편향 없는 데이터셋을 위해 아이템들이 사용자에게 동등한 중요도로 표시될 수 있음
    -   하지만 과도한 탐색을 적용하면 좋지 않은 사용자 경험을 제공함
-   서빙 편향을 완화하는 방법은 다음과 같음

### 입실론-그리디 탐색<sup>$\varepsilon$​-greedy search</sup>

-   서빙 편향을 가장 간단하게 완화하는 방법
-   학습 데이터셋에 임의의 데이터를 추가함
    -   $1-\varepsilon$의 확률로 추천 랭킹 점수가 있는 아이템을 추천하고 나머지 $\varepsilon$ 확률로 다른 아이템을 무작위로 균일하게 선택해서 추천함
-   단순하지만 실무적으로 밴딧 기법과 같은 고급 기법보다 좋은 성능을 보일 때가 많음

### 컨텍스추얼 밴딧<sup>Contextual bandit</sup>

-   대표적으로 톰슨 샘플링<sup>Thompson sampling</sup>과 UCB (Upper Confidence Bound)가 있음
-   [톰슨 샘플링](https://otzslayer.github.io/ml/2022/01/07/about-multi-armed-bandit.html#thompson-sampling)
    -   모델 예측의 사후 분포에서 무작위로 샘플링해 아이템을 추천
    -   가장 가치가 높은 아이템을 선택하는 확률적 접근 방식
-   [UCB](https://otzslayer.github.io/ml/2022/01/07/about-multi-armed-bandit.html#upper-confidence-bound-ucb)
    -   모델 예측에 불확실성 추정치를 추가해 얻은 confidence bound가 가장 높은 아이템을 선택하여 탐색 촉진
-   여러 테크 기업에서 사용함
    -   트위터
        -   [Guo, Dalin, et al. "Deep bayesian bandits: Exploring in online personalized recommendations." *Proceedings of the 14th ACM Conference on Recommender Systems*. 2020.](https://arxiv.org/abs/2008.00727)
    -   야후
        -   [Li, Lihong, et al. "A contextual-bandit approach to personalized news article recommendation." *Proceedings of the 19th international conference on World wide web*. 2010.](https://leehyejin91.github.io/post-contextual_bandit/)
    -   구글
        -   [Chen, Minmin, et al. "Top-k off-policy correction for a REINFORCE recommender system." *Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining*. 2019.](https://arxiv.org/abs/1812.02353)

### 인과 추론<sup>Causal inference</sup>

-   관심 결과에 대한 대체 조치의 인과 효과를 추정하는 것이 목표
-   추천 시스템에서는 무작위화 전략을 사용해 정확한 [반사실적 추정치](q4_08.md#%EB%B0%98%EC%82%AC%EC%8B%A4%EC%A0%81-%EC%B6%94%EB%A1%A0-%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%ACcontextual-inference-framework)를 얻어 중요도 샘플링을 수행해 데이터 가중치를 재조정
-   마이크로소프트에서는 광고 예측에 이 기법을 적용함
    -   [Bottou, Léon, et al. "Counterfactual Reasoning and Learning Systems: The Example of Computational Advertising." *Journal of Machine Learning Research* 14.11 (2013).](https://www.jmlr.org/papers/volume14/bottou13a/bottou13a.pdf)

### 알아가는 기간

-   신규 사용자, 광고 캠페인, 제품 등 신규 아이템을 더 밀어줌<sup>boosting</sup>
    -   시간이나 참여도 증감 같은 신호에 따라 밀어주는 정도를 줄여감
-   콜드 스타트 문제의 서빙 편향을 완화하는데 도움이 됨
    -   최신 데이터에 더 높은 가중치를 부여하고 시간에 따라 점차 가중치를 줄여감
-   이 접근 방식은 가짜<sup>spurious</sup> 신호 학습, 다양성과 콘텐츠 탐색의 부족 등 문제는 개선하지 못함