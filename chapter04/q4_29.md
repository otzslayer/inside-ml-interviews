# Q4.29 랭킹 모델 아키텍처

> [!Tip]
>
> 🙋  모델 아키텍처가 어떤 모습일지 설명하세요.

-   로지스틱 회귀
    -   단순성, 확장성, 해석 가능성이 있어 널리 사용되어 왔음
    -   희소한 피처는 원-핫 인코딩을 통해 사용
    -   기억<sup>Memorization</sup> 효과를 위해 희소한 피처를 교차하여 사용하는 경우가 많음
        -   수동 피처 엔지니어링이 필요하다는 단점이 있음
    -   데이터에서 복잡한 패턴을 포착하기엔 capacity가 부족함
-   DNN
    -   각 피처에 대한 저차원의 dense embedding vector를 학습해서 사용
        -   피처 엔지니어링에 대한 부담이 줄어듦
    -   대상-아이템 피처 간의 희소한 상호 작용에 대한 효과적인 저차원 표현을 학습하는 데 어려움이 있음
        -   특히 niche item에 대해서 심함
-   Wide & Deep Architecture
    -   [Cheng, Heng-Tze, et al. "Wide & deep learning for recommender systems." *Proceedings of the 1st workshop on deep learning for recommender systems*. 2016.](https://leehyejin91.github.io/post-wide_n_deep/)
    -   선형 모델과 DNN의 조합을 사용해 단일 모델로 기억 효과와 일반화 능력을 모두 얻는 방법
        -   선형 및 신경망 접근 방식의 장점을 결합하기 위해 피처 간 상호 작용을 포착할 수 있도록 추가 기법 도입
        -   교차 모델
            -   구글의 Deep & Cross Network
                -   [Wang, Ruoxi, et al. "Deep & cross network for ad click predictions." *Proceedings of the ADKDD'17*. 2017. 1-7.](https://dl.acm.org/doi/pdf/10.1145/3124749.3124754)
            -   DCN v2
                -   [Wang, Ruoxi, et al. "Dcn v2: Improved deep & cross network and practical lessons for web-scale learning to rank systems." *Proceedings of the web conference 2021*. 2021.](https://arxiv.org/pdf/2008.13535)
                -   <img src="https://production-media.paperswithcode.com/methods/Screen_Shot_2021-08-06_at_10.34.24_AM.png" alt="DCN-V2 Explained | Papers With Code" style="zoom:50%;" />
                -   각 교차 레이어는 이전 교차 레이어와 임베딩 레이어 간의 상호 작용 함수
                    -   교차 레이어는 아다마르 곱을 사용함
        -   Factorization Machine
            -   DeepFM
                -   [Guo, Huifeng, et al. "DeepFM: a factorization-machine based neural network for CTR prediction." *arXiv preprint arXiv:1703.04247* (2017).](https://leehyejin91.github.io/post-deepfm/)
                -   <img src="https://d2l.ai/_images/rec-deepfm.svg" alt="21.10. Deep Factorization Machines — Dive into Deep Learning 1.0.3  documentation" style="zoom:67%;" />
                -   피처들의 2차 상호 작용을 포착하는 내적 유닛과 더불어 1차 피처를 포착하는 덧셈 유닛도 있음
            -   xDeepFM
                -   [Lian, Jianxun, et al. "xdeepfm: Combining explicit and implicit feature interactions for recommender systems." *Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining*. 2018.](https://arxiv.org/pdf/1803.05170)
    -   다중 작업 학습<sup>Multi-task Learning</sup> (MTL)
        -   Multi-gate Mixture-of-Experts (MMoE)
            -   [Ma, Jiaqi, et al. "Modeling task relationships in multi-task learning with multi-gate mixture-of-experts." *Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining*. 2018.](https://dl.acm.org/doi/pdf/10.1145/3219819.3220007)
            -   <img src="https://blog.reachsumit.com/img/posts/2023/moe-for-recsys/mmoe.png" alt="MMoE" style="zoom:60%;" />
                -   각 작업은 전문가 결과를 결합하기 위해 서로 다른 게이트를 사용함
                -   하단 레이어는 입력 피처와 임베딩의 연결일 수도 있고, DCN처럼 출력층과 같은 피처 상호작용의 결과일 수도 있음
            -   동시에 여러 작업을 학습하는 데 효과적
                -   예를 들어 하나의 모델이 클릭 수와 좋아요 수를 모두 최적화할 수 있음
-   어텐션 기반 모델과 트랜스포머 기반 모델
    -   어텐션 메커니즘
        -   입력 데이터에서 관련 정보가 있는 부분에 집중하기 위해 사용
        -   Query, Key, Value 세 가지 요소로 구성
            -   Query : 입력 요소 (ex. 사용자의 현재 상호 작용)
            -   Key : 어텐션을 주려는 요소 (ex. 사용자의 이전 상호 작용)
            -   Value : Key에 대해 추출하려는 정보 (ex. Key의 상호작용 시맨틱<sup>semantic</sup> 요소)
    -   유사도 점수
        -   Query와 Key는 유사도 점수를 계산하는데 사용됨
        -   일반적으로 내적을 사용하며, 계산된 점수는 각 요소에 얼마나 집중해야 하는지 나타냄
    -   소프트맥스 함수
        -   결과 유사도 점수에 소프트맥스를 적용해 Key에 관한 확률 분포를 만듦
            -   Key와 Query의 상관 정도를 나타냄
            -   만들어진 소프트맥스 분포는 각 Key에 관한 정보를 나타내는 Value 벡터에 가중치를 부여할 때 사용함
            -   가중치가 곱해진 Value 벡터를 합산해 현재 입력에 대한 어텐션 레이어의 출력을 생성함
                -   출력값은 추가 처리를 위해 피드포워드 네트워크로 전달됨
    -   멀티헤드 어텐션
        -   복수의 Query, Key, Value 집합을 만들어 사용
            -   각 헤드 별로 Query, Key, Value를 만들기 위한 임베딩 행렬이 따로 사용됨



-   최신 Pointwise LTR 모델의 아키텍처 구성 요소 (1, 4, 6, 7은 반드시 있어야 함)
    1.   임베딩과 같은 피처 표현이 입력값이 됨
    2.   어텐션 네트워크는 사용자의 과거 행동과 같은 순차적 정보를 포착함
    3.   피처 상호 작용은 Deep Crossing (DCN, DCN v2) 또는 임베딩 교차(DeepFM, xDeepFM, DLRM)의 형태로 만들어짐
    4.   임베딩을 concatenate함
    5.   다중 작업 학습에서 네트워크는 여러 분기로 나눠지는데, 종종 MMoE나 Progressive Layered Extraction(PLE) 계층을 활용해 목표 간 파라미터를 공유함
    6.   심층 신경망은 일반적으로 64\~1024개의 히든 뉴런이 있는 히든 레이어 2\~3개로 구성된 MLP임
    7.   손실은 일반적으로 Sigmoid Cross Entropy를 사용하지만 항상 그렇지는 않음



-   업계에서 활용하는 랭킹 모델 정보

| 회사           | 도메인                               | 아키텍처                                     | 레퍼런스                                                     |
| -------------- | ------------------------------------ | -------------------------------------------- | ------------------------------------------------------------ |
| 유튜브         | 영상 추천                            | MMoE를 통한 다중 작업                        | [Zhao, Zhe, et al. "Recommending what video to watch next: a multitask ranking system." *Proceedings of the 13th ACM Conference on Recommender Systems*. 2019.](https://daiwk.github.io/assets/youtube-multitask.pdf) |
| 링크드인       | 홈페이지 피드                        | 다중 작업 학습                               | Ian, Ackerman, and Kataria Saurabh. “Homepage Feed Multi-Task Learning Using Tensorflow.” *LinkedIn*, 3 June 2021, https://www.linkedin.com/blog/engineering/feed/homepage-feed-multi-task-learning-using-tensorflow. Accessed 28 July 2024. |
| 텐센트         | 칸디앤<sup>Kandian</sup> 피드        | Contrastive Sharing Network를 통한 다중 학습 | [Bai, Ting, et al. "A contrastive sharing model for multi-task recommendation." *Proceedings of the ACM Web Conference 2022*. 2022.](https://tbbaby.github.io/pub/www22.pdf) |
| 스포티파이     | 음악 추천                            | 다중 작업 학습                               | [Saravanou, Antonia, et al. "Multi-Task Learning of Graph-based Inductive Representations of Music Content." *ISMIR*. 2021.](https://rishabhmehrotra.com/papers/ismir2021-multi-task-representations.pdf) |
| 스냅챗         | 광고 랭킹                            | Deep Crossing - PLE를 통한 다중 작업         | Machine Learning for Snapchat Ad Ranking. (2022, February 11). Snap Engineering. Retrived June 6, 2024, from https://eng.snap.com/machine-learning-snap-ad-ranking |
| 바이트댄스     | 바이트플러스<sup>BytePlus</sup> 추천 | 임베딩 교차(Factorization Machine)           | [Liu, Zhuoran, et al. "Monolith: real time recommendation system with collisionless embedding table." *arXiv preprint arXiv:2209.07663* (2022).](https://arxiv.org/pdf/2209.07663?trk=public_post_comment-text) |
| 알리바바       | 타오바오 제품 추천                   | 어텐션 네트워크-다중 작업 학습               | [Zheng, Yukun, et al. "Multi-Objective Personalized Product Retrieval in Taobao Search." *arXiv preprint arXiv:2210.04170* (2022).](https://arxiv.org/pdf/2210.04170) |
| 화웨이         | 뉴스 추천                            | 어텐션 네트워크-다중 작업 학습               | [Bi, Qiwei, et al. "Mtrec: Multi-task learning over bert for news recommendation." *Findings of the Association for Computational Linguistics: ACL 2022*. 2022.](https://aclanthology.org/2022.findings-acl.209.pdf) |
| 홈디포         | 제품 추천                            | 트랜스포머-다중 작업 학습                    | [Shalaby, Walid, et al. "M2TRec: Metadata-aware Multi-task Transformer for Large-scale and Cold-start free Session-based Recommendations." *Proceedings of the 16th ACM Conference on Recommender Systems*. 2022.](https://arxiv.org/pdf/2209.11824) |
| 콰이쇼우       | 영상 추천                            | 어텐션 네트워크-MMoE를 통한 다중 학습        | [Gong, Xudong, et al. "Real-time short video recommendation on mobile devices." *Proceedings of the 31st ACM international conference on information & knowledge management*. 2022.](https://arxiv.org/pdf/2208.09577) |
| 마이크로소프트 | 뉴스 추천                            | 어텐션 네트워크                              | [Wu, Chuhan, et al. "Empowering news recommendation with pre-trained language models." *Proceedings of the 44th international ACM SIGIR conference on research and development in information retrieval*. 2021.](https://arxiv.org/pdf/2104.07413) |

