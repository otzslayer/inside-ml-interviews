# Q4.9 데이터셋 유형

> [!Tip]
> 
> 🙋 학습 데이터셋을 어떻게 수집하나요?

-   추천 시스템을 위한 학습 데이터 수집은 쉽지 않음
    -   사용자와 아이템을 잘 나타낼 수 있어야 함
    -   데이터의 양이 충분히 커야 함
    -   편향의 영향을 최소화하는 방식으로 구성되어야 함

> [!Tip]
> 
> 🙋 추천 후보 생성 단계에서 사용하는 데이터 수집 기술을 설명하세요.

-   후보 생성 단계에서는 네거티브 샘플링을 사용함
    -   모든 네거티브 아이템을 최적화에 사용하면 계산 비용이 너무 높음
    -   포지티브 아이템만 사용하면 네거티브 아이템에 대해 과예측<sup>overprediction</sup>을 하는 폴딩<sup>folding</sup> 현상이 발생할 수 있음
        -   *실제로 포지티브 아이템만 학습에 사용하는 실수를 저지른 적이 있는데 랭킹 자체가 망가져버림*

## 네거티브 샘플링 기법

### 균일 샘플링

-   사용자의 이력에 없는 아이템을 네거티브 샘플로 무작위 추출
    -   [Rendle, Steffen, et al. "BPR: Bayesian personalized ranking from implicit feedback." *arXiv preprint arXiv:1205.2618* (2012).](https://otzslayer.github.io/ml/2022/02/19/bayesian-personalized-ranking.html)

-   구현이 간단함
-   모델이 포지티브 아이템과 유사도가 높은 네거티브 아이템을 효과적으로 구별하지 못할 수 있음

### 인기 기반 샘플링

-   인기를 기반으로 네거티브 아이템을 샘플링
    -   인기가 많은 아이템보다 적은 아이템이 선호됨
        -   [Lerer, Adam, et al. "Pytorch-biggraph: A large scale graph embedding system." *Proceedings of Machine Learning and Systems* 1 (2019): 120-131.](https://proceedings.mlsys.org/paper_files/paper/2019/file/1eb34d662b67a14e3511d0dfd78669be-Paper.pdf)
-   모델이 틈새<sup>niche</sup> 아이템과 잘 알려진 아이템을 구별하는 데 도움이 되기도 하지만 인기 아이템에는 과한 페널티를 야기할 수 있음

### 인기 감쇠 샘플링

-   샘플링할 때 네거티브 아이템의 인기를 감쇠<sup>dampen</sup>시킴
    -   What is Candidate Sampling. (n.d.). TensorFlow. Retrieved Jun 19, 2024, from https://www.tensorflow.org/extras/candidate_sampling.pdf

-   인기가 적거나 덜 알려진 아이템을 발견하는 데 유용하지만 사용자와 관련이 없는 인기 아이템을 일부 놓칠 수 있음
    -   node2vec 참고
        -   [Grover, Aditya, and Jure Leskovec. "node2vec: Scalable feature learning for networks." *Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining*. 2016.](https://otzslayer.github.io/cs224w/2023/06/04/cs224w-03.html#node2vec)

### 원거리 네거티브 샘플링

-   포지티브 아이템과 유사하지 않은 네거티브 아이템이나 모델 점수가 낮은 아이템 선택
    -   포지티브 아이템에 가까운 노드<sup>node</sup>는 포지티브로 간주하고 멀리 있는 노드는 네거티브로 간주
    -   직관적일 수 있지만 랜덤 샘플링과 마찬가지로 정보가 없는<sup>uninformative</sup> 네거티브 샘플을 생성할 수 있음
    -   *저자가 데이터를 그래프 관점에서 바라보고 있는 듯함*

### 하드 네거티브 샘플링

-   가장 널리 사용하는 방법
-   포지티브 아이템과 유사도가 높거나 관련성이 클 법한 아이템을 선택
    -   가령 모델 점수가 높은 아이템을 선택함
        -   [Zhang, Weinan, et al. "Optimizing top-n collaborative filtering via dynamic negative item sampling." *Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval*. 2013.](https://wnzhang.net/papers/lambdarankcf-sigir.pdf)
    -   포지티브 아이템과 유사도가 높지만 관련성이 작은 아이템을 추천하지 않는데 도움이 됨
    -   위음성<sup>false negative</sup>이 발생할 수도 있음
-   예시
    -   일반적으로는 모델 점수가 높을 수록 선택될 가능성이 커지는 방식으로 네거티브 아이템을 샘플링
        -   PinSage
            -   [Ying, Rex, et al. "Graph convolutional neural networks for web-scale recommender systems." *Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining*. 2018.](https://otzslayer.github.io/cs224w/2023/07/12/cs224w-13.html#pinsage)
        -   RotatE
            -   [Sun, Zhiqing, et al. "Rotate: Knowledge graph embedding by relational rotation in complex space." *arXiv preprint arXiv:1902.10197* (2019).](https://process-mining.tistory.com/181?category=968053)
    -   몬테 카를로 네거티브 샘플링<sup>Monte Carlo Negative Sampling</sup>(MCNS)
        -   [Yang, Zhen, et al. "Understanding negative sampling in graph representation learning." *Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery & data mining*. 2020.](https://arxiv.org/pdf/2005.09863)
        -   랜덤 워크를 활용해 탐색과 활용의 균형을 찾아 네거티브 아이템을 샘플링함
        -   네거티브 샘플은 예측된 모델 점수에 비례해 선택
    -   GAN을 네거티브 샘플링을 위한 프레임워크로 사용
        -   KBGAN은 생성자로 소프트맥스 기반 모델을 사용해 판별자를 혼동시킬만한 네거티브 아이템을 샘플링함
            -   [Cai, Liwei, and William Yang Wang. "Kbgan: Adversarial learning for knowledge graph embeddings." *arXiv preprint arXiv:1711.04071* (2017).](https://arxiv.org/pdf/1711.04071)
        -   판별자로는 마진 손실 기반 모델 사용
            -   많은 양의 네거티브 샘플을 만들기엔 비효율적일 수 있음

> [!Tip]
> 
> 🙋 사전 랭킹 단계에서 사용하는 데이터 수집 기술을 설명하세요.

### 편향 샘플링

-   사전 랭킹 단계에서 살아남았거나 사용자에게 서빙된 기록이 있는 후보 샘플링
-   장점
    -   후보들이 다운스트림 단게에서 로깅되므로 수집하기 용이함
    -   모델이 더 강력한 후보로부터 학습할 수 있음
-   단점
    -   모델이 약한 후보를 잘 가려내지 못함
    -   데이터셋이 모델이 수신하는 입력 데이터를 정확히 나타내지 못함
    -   사전 랭킹 모델에 바람직하지 않은 피드백 루프를 제공함
    -   *전반적으로 이미 추천될 것으로 예상되는 아이템에 대한 샘플링으로 인해 피드백 루프가 발생하는 상황*

### 균일 샘플링

-   입력 후보를 완전히 무작위로 샘플링함
-   장점
    -   입력 데이터를 정확하게 나타낼 수 있음
    -   학습 데이터 관점에서 가장 다양한 데이터가 됨
-   단점
    -   일반적으로 사전 랭킹 모델에 사용하는 랭킹 지표(nDCG, MRR, MAP 등)를 사용하기 어려움
    -   일부 학습 기법을 사용할 수 없게 됨
        -   Listwise ranking이나 Top-n 포인트별 레이블 기반 학습을 할 수 없게 됨
    -   *사용자에게 노출된 아이템 목록과 그 레이블이 있어야 하는데 이 상황에선 그런 데이터가 없어서 생기는 단점으로 보임*

### 요청 레벨 샘플링

-   특정 요청 또는 쿼리에 대한 입력 후보를 모두 샘플링함
-   장점
    -   입력 데이터를 정확하게 나타낼 수 있음
    -   학습 옵션, 평가 지표, 반사실적 추론 등의 측면에서 제약이 없음
-   단점
    -   다양성이 낮아짐
    -   최종 결과에는 거의 포함되지 않는 후보나 클릭베이트<sup>clickbait</sup> 느낌의 후보들에 대해 과도한 학습이 이루어질 수도 있음
    -   운영 시스템에서 구현하기 가장 어려운 방법인 경우가 많음

### 요약

-   실무적으로는 여러 방법을 조합해 포괄적인 학습 데이터셋을 구성하는 것이 좋음
    -   예를 들어 학습 시에는 균일 데이터셋을, 평가에는 요청 레벨 데이터셋을 사용하는 형태
    -   요청 레벨 데이터셋을 서브샘플링하여 요청 다양성을 높이거나 관련성 없는 후보 아이템의 발생률을 낮출 수 있음

> [!Tip]
> 
> 🙋 랭킹 단계에서 사용하는 데이터 수집 기술을 설명하세요.

-   일반적으로 헤비 랭킹 모델의 학습 루프는 사용자에게 서빙되는 후보들의 데이터에 대한 스트림 처리를 필요로 함
    -   사용자에게 노출된 후보들에 대한 결과가 모델에 다시 공급 -> 시간에 따라 랭킹 알고리즘이 업데이트되고 개선됨

### 업데이트 빈도

-   데이터 신선도
    -   랭킹 모델을 위한 학습 데이터를 수집할 때 고려해야 할 중요한 요소
-   랭킹 모델을 업데이트 하는 방법
    -   배치
    -   온라인
    -   연속 업데이트
-   업데이트 방법에 따라 데이터 수집 프로세스가 달라짐
    -   배치 업데이트
        -   일반적으로 오프라인 작업을 실행해 로그와 기타 데이터를 학습 저장소로 집계
    -   연속 업데이트
        -   실시간으로 모델에 전송될 연속 데이터 스트림이 필요
        -   복잡한 데이터 처리 및 스토리지 인프라 요소가 포함될 수 있음

### 지연된 피드백

-   많은 실시간 시스템에서 사용자 상호 작용 데이터에는 길고 무작위한 지연이 발생한 후에 레이블이 정해짐
    -   [Ktena, Sofia Ira, et al. "Addressing delayed feedback for continuous training with neural networks in CTR prediction." *Proceedings of the 13th ACM conference on recommender systems*. 2019.](https://arxiv.org/pdf/1907.06558)
    -   모바일 앱 프로모션과 같은 광고 상품의 경우 며칠 또는 몇 주가 지나서 레이블이 생길 수도 있음
        -   Machine Learning for Snapchat Ad Ranking. (2022, February 11). Snap Engineering. Retrived June 6, 2024, from https://eng.snap.com/machine-learning-snap-ad-ranking
-   포지티브 레이블이 생기기 전까지 모든 데이터를 네거티브 샘플로 간주할 수도 있음
    -   하지만 지연된 포지티브 샘플의 사례를 과소예측<sup>underpredict</sup>하는 경향이 생김

### 네거티브 샘플링

-   포티지브 샘플은 일반적으로 전체 후보 수에 비해 훨씬 적음
    -   심각한 클래스 불균형 문제가 발생함
        -   학습 데이터셋이 네거티브 샘플에 편향되어 모델 성능이 저하될 수 있음
    -   모바일 앱 프로모션 시나리오에서 광고 노출이 앱 설치로 이어질 확률은 0.01% 미만일 수 있음
    -   이런 문제를 해결하기 위해 네거티브 샘플링을 실무에서도 많이 활용함

### 탐색/활용<sup>Exploration & Exploitation</sup>

-   헤비 랭커에서 모델은 사용자에게 노출된 이력이 있는 아이템의 레이블 정보만 학습함
    -   잠재적으로 피드백 루프가 발생할 수 있음
    -   데이터셋에 위치 편향, 서빙 편향 등 다양한 편향이 발생할 수 있음
        -   장기적으로 모델 성능에 영향을 미침
-   편향을 완화하기 위해 일정 수준의 탐색을 학습 프로세스에 통합하는 것이 중요함
-   *번역된 내용으로는 정확한 내용을 판단하기 어렵지만 전체적인 내용을 봤을 때 편향 없는 데이터 수집을 위한 탐색/활용 전략으로 보임*
    -   *여기서 말하는 탐색/활용은 강화학습에서 자주 언급되는 Exploration & Exploitation 으로 보임*
    -   [Hong, Liangjie, and Adnan Boz. "An Unbiased Data Collection and Content Exploitation/Exploration Strategy for Personalization." *arXiv preprint arXiv:1604.03506* (2016).](https://arxiv.org/abs/1604.03506)

