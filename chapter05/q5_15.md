# Q5.15 토픽 모델링 평가 지표

>   [!Tip]
>
>   🙋 토픽 모델링 알고리즘의 성능을 어떤 지표로 평가하나요?

- Perplexity
	- 테스트 셋의 로그 가능도(log-likelihood)
	- 학습된 모델이 주어진 테스트 셋 내의 단어들을 관찰할 확률 
	- $$\text{perplexity} = \exp \left\{ -\frac{\sum^M_{d=1} \log(p(w_d))}{N} \right\}$$
		- $p(w_d)$ : 문서별 토픽 분포와 토픽별 단어 분포를 고려해 단어 $w_d$가 관찰될 확률
		- $N$ : 테스트 셋의 총 단어 수
	- 일반적으로 많이 사용하는 지표지만 추출된 토픽의 품질에 대한 인간의 평가와는 상관관계가 약할 수 있음
		- [Chang, Jonathan, et al. "Reading tea leaves: How humans interpret topic models." _Advances in neural information processing systems_ 22 (2009).](https://proceedings.neurips.cc/paper_files/paper/2009/file/f92586a25bb3145facd64ab20fd554ff-Paper.pdf)
- 토픽 일관성
	- 토픽 해석 가능성에 대한 인간의 평가와 더 밀접하게 일치하는 지표
		- [Lau, Jey Han, David Newman, and Timothy Baldwin. "Machine reading tea leaves: Automatically evaluating topic coherence and topic model quality." _Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics_. 2014.](https://aclanthology.org/E14-1056.pdf)
	- 토픽의 상위 단어들이 서로 얼마나 관련되어 있는지 측정해 일반적으로 일관성<sup>coherence</sup> 점수가 높을 수록 토픽이 더 일관되고 해석 가능함
	- 보통 점별 상호 정보량(Pointwise Mutual Information, PMI) 사용
- 토픽 다양성
	- 모델이 생성한 토픽의 폭을 평가하는 보완적 지표
	- 모든 토픽의 상위 25개 단어 중 고유 단어의 비율 측정
	- 다양성<sup>Diversity</sup> 점수가 높을 수록 더 넓은 범위의 토픽 포착
- 다운스트림 성능
	- 다운스트림 모델의 성능을 확인해 토픽 모델이 관련 토픽을 얼마나 잘 포착했는지 평가