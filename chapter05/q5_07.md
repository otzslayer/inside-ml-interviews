# Q5.7 비지도 학습 피처

>   [!Tip]
>
>   🙋 범주형 피처를 설명하세요.

-   기존 클러스터링 알고리즘 대부분은 기본적으로 범주형 피처를 허용하지 않음
    -   수치형으로 변환하여 사용해야 함
    -   일부 가능한 알고리즘이 있음
        -   k-prototypes
            -   Huang, Z. "Clustering Large Data Sets With Mixed Numeric And Categorical Values," Proceedings Of 1st Pacific-Asia Conference on Knowledge Discouvery And Data Mining." (1997).
        -   딥 임베딩 클러스터링<sup>Deep Embedding Clustering</sup> (DEC)
            -   [Xie, Junyuan, Ross Girshick, and Ali Farhadi. "Unsupervised deep embedding for clustering analysis." *International conference on machine learning*. PMLR, 2016.](https://proceedings.mlr.press/v48/xieb16.pdf)
-   범주형 피처를 연속형 피처로 변환하는 방법
    -   원-핫 인코딩
        -   범주형 피처의 각 고윳값에 대해 새로운 이진 피처 생성
        -   피처 공간을 고차원으로 만들기 때문에 계산 비용 증가
    -   레이블 인코딩
        -   피처의 각 범주에 고유한 정수를 할당
        -   범주 간에 정수로 표시할 수 있는 관계가 있을 때 잘 작동함
            -   값 크기 비교 가능하거나
    -   순서<sup>Ordinal</sup> 인코딩
        -   레이블 인코딩과 비슷하지만 범주의 순서를 나타냄
        -   범주 사이에 실제 순서 관계가 없는 경우 잘못된 정보가 들어갈 수 있음

>   [!Tip]
>
>   🙋 연속값 피처를 설명하세요.

-   로그 변환
    -   거듭제곱 법칙 분포를 따르는 피처(ex. 조회 수 등)의 왜도와 산포도를 줄임
    -   추가 데이터가 필요하진 않지만 음수는 처리할 수 없음
-   z-점수 스케일링(정규화<sup>normalization</sup>)
    -   정규 분포를 따르는 피처(ex. 아이템 평점)를 표준화
    -   평균과 표준 편차를 계산해야 하므로 로그 변환보다 더 많은 데이터 필요
-   버키팅(ex. 분위수)
    -   피처 분포와 상관 없이 적용할 수 있음
        -   피처값을 기준으로 동일한 크기의 저장소들을 생성함
    -   대략 버킷 수의 10배에 달하는 데이터가 필요함
        -   데이터 준비 | Machine Learning. (2022, July 18). Google Developers. Retrieved Sep 16, 2024, from https://developers.google.com/machine-learning/clustering/prepare-data?hl=ko
    -   일부 정보가 손실되지만 불규칙한 분포를 효과적으로 처리할 수 있음

>   [!Tip]
>
>   🙋 누락된 피처를 설명하세요.

-   클러스터링은 유사도에 기반하므로 모든 열에 값이 존재하는 것이 중요함

-   누락된 피처의 경우

    -   완전히 제거하거나

    -   값을 대치하거나

    -   누락된 케이스가 적다면 아예 제거하거나

        

