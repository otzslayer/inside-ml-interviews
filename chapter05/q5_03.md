# Q5.3 í† í”½ ëª¨ë¸ë§ ê¸°ë²•

>   [!Tip]
>
>   ğŸ™‹ ë‰´ìŠ¤ ê¸°ì‚¬ì— ì–´ë–¤ í† í”½ë“¤ì´ ë“¤ì–´ ìˆëŠ”ì§€ ì‹ë³„í•˜ëŠ” ML ì‹œìŠ¤í…œì„ êµ¬ì¶•í•©ë‹ˆë‹¤. í† í”½ ëª¨ë¸ë§ ê¸°ë²•ì—ëŠ” ì–´ë–¤ ê²ƒì´ ìˆë‚˜ìš”?

### ë‹¨ì–´ ê¸°ë°˜ ê¸°ìˆ 

-   ë‹¨ì–´ ì„ë² ë”© ë˜ëŠ” ë‹¨ì–´ ë¹ˆë„ ê¸°ë°˜ ë°©ë²•ì„ ì‚¬ìš©í•´ íŠ¹ì • í† í”½ì— ê´€í•œ ë‹¨ì–´ê°€ ìˆëŠ”ì§€ í™•ì¸
    -   êµ¬í˜„ì´ ê°„ë‹¨í•˜ê³  ë¹ ë¥´ì§€ë§Œ í† í”½ ê°„ì˜ ë³µì¡í•œ ê´€ê³„ë¥¼ í¬ì°©í•˜ì§€ëŠ” ëª»í•¨
    -   [Meddeb, Amna, and Lotfi Ben Romdhane. "Using topic modeling and word embedding for topic extraction in Twitter." *Procedia Computer Science* 207 (2022): 790-799.](https://www.sciencedirect.com/science/article/pii/S1877050922010158/pdf?md5=a23ab885400883086f7a5fade38383e2&pid=1-s2.0-S1877050922010158-main.pdf)
-   êµ¬í˜„ ë°©ë²•
    1.   í‚¤ì›Œë“œ ì¶”ì¶œ
         -   ê° ë¬¸ì„œì—ì„œ ê°€ì¥ ë‘ë“œëŸ¬ì§„ í‚¤ì›Œë“œ ì¶”ì¶œ
         -   TF-IDF, Chunking, í† í”½ ë‹¨ì–´ì™€ ê°™ì€ ë‹¤ì–‘í•œ ê¸°ë²•ìœ¼ë¡œ ìˆ˜í–‰
    2.   ë‹¨ì–´ ì„ë² ë”©
         -   ì¶”ì¶œí•œ ê° í‚¤ì›Œë“œ ë˜ëŠ” ë¬¸êµ¬ë¥¼ GloVeì™€ ê°™ì€ ë‹¨ì–´ ì„ë² ë”©ì„ ì‚¬ìš©í•´ ë‚®ì€ ì°¨ì› ë²¡í„°ë¡œ í‘œí˜„
             -   [Wu, Yongliang, Shuliang Zhao, and Wenbin Li. "Phrase2Vec: phrase embedding based on parsing." *Information Sciences* 517 (2020): 100-127.](https://sci-hub.se/downloads/2020-07-19/c7/wu2019.pdf)
             -   [Pennington, Jeffrey, Richard Socher, and Christopher D. Manning. "Glove: Global vectors for word representation." *Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)*. 2014.](https://aclanthology.org/D14-1162.pdf)
    3.   ì„ë² ë”© ìœ ì‚¬ë„
         -   í‚¤ì›Œë“œì™€ í† í”½ ì‹œë“œ ë‹¨ì–´ë¥¼ ì„ë² ë”© ê±°ë¦¬ ê¸°ë°˜ìœ¼ë¡œ ë§¤ì¹­
         -   í–‰ë ¬ ë¶„í•´ì™€ ê°™ì€ ê¸°ìˆ ì„ ì‚¬ìš©í•´ ê³µìœ  ì„ë² ë”© ê³µê°„ì„ í•™ìŠµì‹œí‚¤ë©´ í‚¤ì›Œë“œ ì„ë² ë”©ê³¼ í† í”½ ì„ë² ë”©ì˜ ìœ ì‚¬ë„ë¥¼ ì§ì ‘ ë¹„êµí•  ìˆ˜ ìˆìŒ

### í–‰ë ¬ ë¶„í•´

-   ë‹¨ì–´ ë™ì‹œ ë°œìƒ<sup>Word co-occurrences</sup> ë˜ëŠ” ë‹¨ì–´-ë¬¸ì„œ ë¹ˆë„<sup>term-document counts</sup> í–‰ë ¬ì„ ì ì¬ í† í”½ ë° í•´ë‹¹ ê°€ì¤‘ì¹˜ì˜ ì €ì°¨ì› í–‰ë ¬ë¡œ ì¸ìˆ˜ ë¶„í•´
    -   ì ì¬ ì˜ë¯¸ ë¶„ì„<sup>Latent Semantic Analysis</sup>(LSA)ê°€ ë„ë¦¬ ì‚¬ìš©ë¨
        -   Latent semantic analysis. (n.d.). Wikipedia. Retrieved September 6, 2024, from https://en.wikipedia.org/wiki/Latent_semantic_analysis
    -   ë¹„ìŒìˆ˜ í–‰ë ¬ ë¶„í•´<sup>Non-negative Matrix Factorization</sup>(NMF)ëŠ” í–‰ë ¬ ì›ì†Œê°€ ìŒìˆ˜ê°€ ì•„ë‹ˆì–´ì•¼ í•œë‹¤ëŠ” ì œì•½ì„ ë¶€ê³¼í•´ í•´ì„ ê°€ëŠ¥ì„±ì´ í° ê²°ê³¼ë¥¼ ì–»ìŒ
        -   ê²°ê³¼ë¡œ ì–»ëŠ” ë²¡í„°ë¥¼ ë§ì…ˆì´ ê°€ëŠ¥í•œ ë¬¸ì„œ í† í”½ ìš”ì†Œë¡œ í•´ì„í•  ìˆ˜ ìˆê¸° ë•Œë¬¸
        -   [Arora, Sanjeev, Rong Ge, and Ankur Moitra. "Learning topic models--going beyond SVD." *2012 IEEE 53rd annual symposium on foundations of computer science*. IEEE, 2012.](https://arxiv.org/pdf/1204.1956)

### í™•ë¥ ì  í† í”½ ëª¨ë¸ë§

-   ê° ë¬¸ì„œë¥¼ í† í”½ë“¤ì˜ í˜¼í•©ìœ¼ë¡œ ëª¨ë¸ë§í•˜ê³  ê° í† í”½ì„ ë‹¨ì–´ì— ëŒ€í•œ ë¶„í¬ë¡œ ëª¨ë¸ë§
-   ì ì¬ ë””ë¦¬í´ë ˆ í• ë‹¹<sup>Latent Dirichlet Allocation</sup>(LDA)ë¥¼ ì£¼ë¡œ ì‚¬ìš©í•¨
    -   í† í”½ ë¶„í¬ ì¶”ì •ì„ ìœ„í•´ ë² ì´ì§€ì•ˆ ì¶”ë¡  ì‚¬ìš©
    -   2ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤
        -   ë””ë¦¬í´ë ˆ ë¶„í¬ì—ì„œ í† í”½ í™•ë¥  ì§‘í•©ì„ ì¶”ì¶œí•œ ë‹¤ìŒ í•´ë‹¹ í† í”½ì—ì„œ ë‹¨ì–´ ì§‘í•© ì¶”ì¶œ
        -   ê´€ì°°ëœ ë°ì´í„°ì˜ ê°€ëŠ¥ë„ë¥¼ ìµœëŒ€í™”í•˜ëŠ” ë°˜ë³µ ì‘ì—…ì„ ìˆ˜í–‰í•´ ê° ë¬¸ì„œì— ëŒ€í•´ ê°€ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ í† í”½ ë¶„í¬ ì¶”ë¡ 
    -   [Blei, David M., Andrew Y. Ng, and Michael I. Jordan. "Latent dirichlet allocation." *Journal of machine Learning research* 3.Jan (2003): 993-1022.](https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf?ref=http://githubhelp.com)
-   ê³„ì¸µì  ë””ë¦¬í´ë ˆ ê³¼ì •<sup>Hierarchical Dirichlet Process</sup>(HDP)
    -   LDAì˜ í™•ì¥íŒ
    -   ë°ì´í„°ì—ì„œ ë¬´í•œí•œ ê°œìˆ˜ì˜ í† í”½ ì¶”ë¡  ê°€ëŠ¥
    -   [Teh, Yee, et al. "Sharing clusters among related groups: Hierarchical Dirichlet processes." *Advances in neural information processing systems* 17 (2004).](https://proceedings.neurips.cc/paper_files/paper/2004/file/fb4ab556bc42d6f0ee0f9e24ec4d1af0-Paper.pdf)
-   Correlated Topic Models (CTM)
    -   í† í”½ì˜ ìƒê´€ê´€ê³„ë¥¼ í—ˆìš©í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ LDA í™•ì¥
    -   í† í”½ì´ ê³µìœ  ê³µë¶„ì‚° í–‰ë ¬ì„ ì‚¬ìš©í•˜ëŠ” ë‹¤ë³€ëŸ‰ ê°€ìš°ìŠ¤ ë¶„í¬ì—ì„œ ìƒì„±ëœë‹¤ê³  ê°€ì •í•¨
    -   [Blei, David, and John Lafferty. "Correlated topic models." *Advances in neural information processing systems* 18 (2006): 147.](https://www.cs.cmu.edu/afs/cs/usr/lafferty/www/pub/ctm.pdf)

### ì‹ ê²½ë§ í† í”½ ëª¨ë¸

-   ì‹ ê²½ë§ì„ ì‚¬ìš©í•´ ì ì¬ í† í”½ì„ ë°œê²¬í•´ ë¬¸ì„œë¥¼ í† í”½ ë¶„í¬ë¡œ í‘œí˜„
-   í™•ë¥ ì  í† í”½ ëª¨ë¸ë§ì— ë¹„í•´ ê°œì„ ì ì´ ìˆìŒ
    -   í† í”½ ë° ë‹¨ì–´ ë¶„í¬ë¥¼ í™•ë¥  ë²¡í„° ë˜ëŠ” ì„ë² ë”©ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŒ -> LDAë„ ê°–ê³  ìˆìŒ
    -   ëŒ€ê·œëª¨ corpusë¡œ í™•ì¥í•˜ê³  GPUë¥¼ í™œìš©í•˜ê¸°ì— íš¨ìœ¨ì 
    -   í…ìŠ¤íŠ¸ ìƒì„±ê³¼ ë¬¸ì„œ ìš”ì•½ ë“± ê³µë™ í•™ìŠµ ëª©ì ì„ ìœ„í•´ ë‹¤ë¥¸ ì‹ ê²½ë§ê³¼ ê²°í•©í•˜ê¸° ìš©ì´
        -   [Wang, Wenlin, et al. "Topic-guided variational autoencoders for text generation." *arXiv preprint arXiv:1903.07137* (2019).](https://arxiv.org/pdf/1903.07137)
        -   [Cui, Peng, Le Hu, and Yuanchao Liu. "Enhancing extractive text summarization with topic-aware graph neural networks." *arXiv preprint arXiv:2010.06253* (2020).](https://arxiv.org/pdf/2010.06253)
-   ì£¼ë¡œ Variational Auto-Encoder (VAE)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•¨
    -   ì…ë ¥ ë°ì´í„°ë¥¼ ì ì¬ ê³µê°„ì— ë§¤í•‘í•˜ê³  ë””ì½”ë”ëŠ” ì ì¬ í‘œí˜„ì„ ë‹¤ì‹œ ì…ë ¥ ê³µê°„ì— ë§¤í•‘í•¨
    -   NTMì˜ ë§¥ë½ì—ì„œ VAEê°€ í† í”½ì„ ì§ì ‘ ëª¨ë¸ë§í•˜ì§€ ì•Šê³  ë¬¸ì„œì˜ ì•”ì‹œì <sup>implicit</sup>ì¸ í‘œí˜„ì„ í•™ìŠµí•˜ëŠ”ë° ì‚¬ìš©ë˜ê±°ë‚˜ í† í”½ í• ë‹¹ ë° í•´ë‹¹ í† í”½ ë‚´ì˜ ë‹¨ì–´ ë¶„í¬ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ëª¨ë¸ë§í•  ìˆ˜ ìˆìŒ
    -   ë””ë¦¬í´ë ˆ ë¶„í¬ê°€ ì‰¬ìš´ ìµœì í™”ë¥¼ ìœ„í•´ ê°€ìš°ì‹œì•ˆ ë“±ìœ¼ë¡œ ëŒ€ì²´ë˜ê¸°ë„ í•¨
        -   [Miao, Yishu, Edward Grefenstette, and Phil Blunsom. "Discovering discrete latent topics with neural variational inference." *International conference on machine learning*. PMLR, 2017.](https://proceedings.mlr.press/v70/miao17a/miao17a.pdf)
    -   LDAì™€ ê°™ì€ í™•ë¥ ì  í† í”½ ëª¨ë¸ë§ë³´ë‹¤ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì„
        -   [Miao, Yishu, Lei Yu, and Phil Blunsom. "Neural variational inference for text processing." *International conference on machine learning*. PMLR, 2016.](https://proceedings.mlr.press/v48/miao16.pdf)

<img src="https://i.imgur.com/h7iGo2n.png" style="zoom:50%;" />